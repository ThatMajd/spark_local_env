{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample code: read data from kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA = StructType([StructField(\"Arrival_Time\",LongType(),True), \n",
    "                     StructField(\"Creation_Time\",LongType(),True),\n",
    "                     StructField(\"Device\",StringType(),True), \n",
    "                     StructField(\"Index\", LongType(), True),\n",
    "                     StructField(\"Model\", StringType(), True),\n",
    "                     StructField(\"User\", StringType(), True),\n",
    "                     StructField(\"gt\", StringType(), True),\n",
    "                     StructField(\"x\", DoubleType(), True),\n",
    "                     StructField(\"y\", DoubleType(), True),\n",
    "                     StructField(\"z\", DoubleType(), True)])\n",
    "\n",
    "# The config packages will try to download the needed packages from maven.org --> you need internet connection\n",
    "spark = SparkSession.builder.appName('demo_app')\\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"512m\")\\\n",
    "    .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4,org.apache.spark:spark-streaming-kafka-0-10-assembly_2.12:2.4.4')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kafka_server = 'dds2020s-kafka.eastus.cloudapp.azure.com:9092'\n",
    "kafka_server = \"kafka:29092\"  # internal name in the Docker network\n",
    "topic = \"activities\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_df = spark.read\\\n",
    "                  .format(\"kafka\")\\\n",
    "                  .option(\"kafka.bootstrap.servers\", kafka_server)\\\n",
    "                  .option(\"subscribe\", topic)\\\n",
    "                  .option(\"startingOffsets\", \"earliest\")\\\n",
    "                  .option(\"failOnDataLoss\",False)\\\n",
    "                  .load()\n",
    "s2 = static_df.select(f.from_json(f.decode(\"value\", \"US-ASCII\"), schema=SCHEMA).alias(\"value\")).select(\"value.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546083 records in frame\n",
      "+-------------+-------------------+--------+-----+------+----+-----+-------------+-------------+-------------+\n",
      "| Arrival_Time|      Creation_Time|  Device|Index| Model|User|   gt|            x|            y|            z|\n",
      "+-------------+-------------------+--------+-----+------+----+-----+-------------+-------------+-------------+\n",
      "|1424686735175|1424686733176178965|nexus4_1|   35|nexus4|   g|stand| 0.0014038086|    5.0354E-4|-0.0124053955|\n",
      "|1424686735378|1424686733382813486|nexus4_1|   76|nexus4|   g|stand|-0.0039367676|  0.026138306|  -0.01133728|\n",
      "|1424686735577|1424686733579072031|nexus4_1|  115|nexus4|   g|stand|  0.003540039| -0.034744263| -0.019882202|\n",
      "|1424686735779|1424688581834321412|nexus4_2|  163|nexus4|   g|stand|  0.002822876|  0.005584717|  0.017318726|\n",
      "|1424686735982|1424688582035859498|nexus4_2|  203|nexus4|   g|stand| 0.0017547607| -0.018981934| -0.022201538|\n",
      "|1424686736186|1424686734188508066|nexus4_1|  236|nexus4|   g|stand| 0.0014038086|  0.010116577|  4.119873E-4|\n",
      "|1424686736385|1424688582438538941|nexus4_2|  283|nexus4|   g|stand|-0.0035858154| -0.008300781|  0.011978149|\n",
      "|1424686736584|1424688582640138062|nexus4_2|  323|nexus4|   g|stand|  6.866455E-4|-0.0018920898|-0.0061798096|\n",
      "|1424686736789|1424688582841554078|nexus4_2|  363|nexus4|   g|stand| 0.0038909912|  0.011993408|-0.0104522705|\n",
      "|1424686736992|1424688583042786988|nexus4_2|  403|nexus4|   g|stand| -0.001449585|  0.014129639| 0.0066375732|\n",
      "|1424686737194|1424686735201603448|nexus4_1|  436|nexus4|   g|stand| 0.0014038086| 0.0037078857| 0.0025482178|\n",
      "|1424686737394|1424686735402195489|nexus4_1|  476|nexus4|   g|stand| 0.0024719238| -0.009109497|-0.0017242432|\n",
      "|1424686737595|1424688583647799551|nexus4_2|  523|nexus4|   g|stand|-0.0046539307|  0.015197754|  0.008773804|\n",
      "|1424686737794|1424686735799800251|nexus4_1|  555|nexus4|   g|stand|-0.0018005371| 0.0015716553|  0.032455444|\n",
      "|1424686737996|1424688584049441397|nexus4_2|  603|nexus4|   g|stand| -0.001449585|-0.0040283203|  0.010910034|\n",
      "|1424686738198|1424688584251010000|nexus4_2|  643|nexus4|   g|stand|-0.0046539307|  0.015197754|  0.021591187|\n",
      "|1424686738417|1424688584472384512|nexus4_2|  679|nexus4|   g|stand| 0.0060272217| 0.0077209473| -0.038223267|\n",
      "|1424686738620|1424688584673983633|nexus4_2|  719|nexus4|   g|stand| -3.814697E-4| -0.015777588| -0.009384155|\n",
      "|1424686738821|1424688584875407249|nexus4_2|  759|nexus4|   g|stand| 0.0049591064|  -0.04675293|  2.288818E-4|\n",
      "|1424686739027|1424686737033510015|nexus4_1|  800|nexus4|   g|stand| -0.038116455|  0.015457153| 0.0025482178|\n",
      "+-------------+-------------------+--------+-----+------+----+-----+-------------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "CPU times: user 3.23 ms, sys: 736 Âµs, total: 3.97 ms\n",
      "Wall time: 8.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# on my pc, there is a fixed 3 sec time for each of count() and show()  ?!\n",
    "# this is probably a spark config: https://stackoverflow.com/questions/59916338/why-is-there-a-delay-in-the-launch-of-spark-executors\n",
    "print(\"%d records in frame\" % s2.count())\n",
    "s2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
